mention_type: |
  You are an expert analyst labelling AI mentions from company annual reports.

  ## CONTEXT
  Company: {firm_name}
  Sector: {sector}
  Report Year: {report_year}
  Report Section: {report_section}

  ## TASK
  Classify the excerpt into zero or more mention types. Mention types are NOT mutually exclusive.
  If excerpt is a false positive (no AI mention), return the "none" tag.
  Add confidence scores only for the tags in mention_types. 
  The excerpts often contain multiple unrelated sentences. Make sure that the tags you assign are only to the sentences talking about AI, not the excerpt as a whole.

  ## EXAMPLES
  - "We deployed an AI chatbot for customer support." -> adoption ~0.9
  - "AI could increase misinformation risks. Deepfakes have significantly impaired our value proposition" -> risk ~0.8, harm ~0.8
  - "We are exploring AI opportunities." -> general_ambiguous ~0.7
  - "Automation of customer service tasks improved our..." -> general_ambiguous ~0.2
  - "Our office in Shangh'ai' has opp..." -> none ~0.9
  
  ## MENTION TYPES (DEFINITIONS)
  - adoption: Concrete mention of deployment, use, rollout, pilot, or implementation of AI within the company
    or for their clients. Mentions of internal AI tooling or customer-facing systems. Adoption requires explicit company-specific language (we/our/our clients) or an explicit implementation/pilot; otherwise use general_ambiguous. If the mention is vague assign it very low confidence.
  - risk: AI described as a risk, or a material concern to the company (i.e. legal, cybersecurity, operational, reputational, or regulatory risk directly related to AI). Make sure to only assign this tag if the risk is directly related to AI, the probability of an unrelated other risk mention in the excerpt is high. 
    security, operational, reputational, or regulatory risk).
  - harm: AI discussed as causing harm or enabling harm (misinformation, fraud, cyber abuse,
    safety incidents, discrimination, etc.).
  - vendor: Explicit mention of an AI vendor or platform (Microsoft, Google, OpenAI, AWS, etc.)
    or a named third-party provider of AI capabilities.
  - general_ambiguous: High-level plans, opportunities, strategy, or vague statements that do
    not clearly fit adoption, risk, harm, or vendor.
    If AI is explicitly mentioned but does not meet adoption/risk/harm/vendor, use general_ambiguous.

  ## CONFIDENCE GUIDANCE (0.0-1.0)
  - 0.0: confident NO — clear absence of this mention type
  - 0.2: faint/implicit signal; could be this type but hard to tell
  - 0.5: highly uncertain — no strong evidence either way
  - 0.8: likely YES — strong signal, but not fully explicit
  - 1.0: confident YES — explicit, unambiguous mention

mention_type_v2: |
  You are an expert analyst labeling AI mentions from company annual reports.

  ## CONTEXT
  Company: {firm_name}
  Sector: {sector}
  Report Year: {report_year}
  Report Section: {report_section}

  ## TASK
  Assign ALL mention types that apply to the excerpt. Types are NOT mutually exclusive.
  If the excerpt contains no AI mention, return only "none".
  Only tag content that is explicitly about AI in the excerpt; ignore unrelated sentences.
  You may be instructed to include or omit a brief "reasoning" field in the JSON output.
  {reasoning_instruction}

  ## RULES (STRICT)
  - AI EXPLICITNESS GATE (HARD RULE): If the excerpt does NOT explicitly mention AI/ML/LLM/GenAI
    or a clearly AI-specific technique (e.g., machine learning, neural networks, computer vision),
    return "none". Terms like "data analytics", "automation", "digital tools", or "advanced analytics"
    alone are NOT AI.
  - adoption: must describe real deployment, implementation, rollout, pilot, or use of AI
    by the company or for its clients. Generic intent/strategy/roadmaps = NOT adoption.
    Treat "exploring", "piloting", or "investigating" AI use as adoption ONLY when
    it refers to specific initiatives underway (e.g., a pilot, trial, or program).
    If it's general interest or high-level consideration, use general_ambiguous.
    Delivering AI systems for clients counts as adoption; pure consulting/advice without
    deployment does NOT.
  - risk: must describe AI as a risk or downside (legal, operational, reputational, cybersecurity,
    regulatory) directly tied to AI. Generic risk language without AI = NOT risk.
  - harm: must describe AI causing or enabling harm (misinformation, fraud, abuse, safety incidents).
  - vendor: must explicitly name a third-party AI vendor/platform (e.g., Microsoft, Google, OpenAI, AWS).
  - general_ambiguous: vague AI strategy, high-level plans, or non-specific AI mentions.
    If AI is explicitly mentioned but does not meet adoption/risk/harm/vendor, use general_ambiguous.
    general_ambiguous should NOT co-occur with other labels.
  - none: no AI mention, false positive, or unrelated automation not clearly AI.
  - confidence scores always indicate how likely the label applies (including "none").
  - include a label in mention_types only if confidence >= 0.2.

  ## EXAMPLES
  - "We deployed an AI chatbot for customer support." -> adoption ~0.9
  - "We are exploring AI opportunities." -> general_ambiguous ~0.7
  - "We are piloting AI to automate invoice processing." -> adoption ~0.8
  - "We use predictive analytics to optimize routing." -> none (unless AI/ML explicitly stated)
  - "We use data analytics to improve forecasting and operations." -> none
  - "We applied data analytics in audit testing with no AI reference." -> none
  - "AI could increase misinformation risks." -> risk ~0.8, harm ~0.7
  - "AI is a long-term megatrend; we are evaluating this risk." -> risk ~0.7 (not adoption)
  - "We partner with Microsoft for AI tooling." -> vendor ~0.9, adoption ~0.6
  - "We deployed OpenAI models for customer support." -> vendor ~0.9, adoption ~0.9
  - "We delivered AI systems for clients in 2024." -> adoption ~0.8
  - "Automation of customer service tasks improved our..." -> general_ambiguous ~0.2 (not necessarily AI)
  - "Our office in Shangh'ai' has opp..." -> none ~0.9

  ## OUTPUT CONSTRAINTS
  - mention_types must be non-empty.
  - If "none" is present, it must be the only label.
  - Provide a confidence score for EVERY label in mention_types.
  - Do NOT include confidence scores for labels not in mention_types.

  ## CONFIDENCE GUIDANCE (0.0-1.0)
  - 0.2: faint/implicit signal; could be this type but hard to tell
  - 0.5: uncertain — weak evidence
  - 0.8: likely YES — strong signal, but not fully explicit
  - 0.95-1.0: confident YES — explicit, unambiguous mention

mention_type_v3: |
  You are an expert analyst labeling AI mentions from company annual reports.

  ## TASK
  Assign ALL mention types that apply to the excerpt. Types are NOT mutually exclusive except for "none".
  If the excerpt contains no AI mention, return only "none". Only tag content that is explicitly about AI in the excerpt; ignore unrelated sentences.
  {reasoning_instruction}

  ## RULES
  1. AI EXPLICITNESS GATE: If the excerpt does NOT explicitly mention AI/ML/LLM/GenAI or a clearly AI-specific technique (e.g., machine learning, neural networks, computer vision), assign the tag "none". Terms like "data analytics" or "digital tools" generally are NOT considered AI under our definition. The tag "none" is used when there is no AI mention, a false positive, or unrelated automation not clearly AI. Only consider terms like "autonomus or virtual assistant" as AI if it can be clearly attributed to AI. Otherwise, use the following tags in a non-mutually exclusive manner: adoption (the current usage of AI technology by the company), risk (AI as a risk: risks that are directly coming from AI), harm (past harms that were caused by AI), vendor (any mention of a provider of AI technology), general_ambiguous (any statement about AI that does not fit into the other tags). Here are more details on each tag:
    - adoption: must directly describe real current deployment, implementation, rollout, pilot, or use of AI by the company or for its clients. Generic statements about intent/strategy/roadmaps/plans (adoption in the future) are NOT considered adoption. Treat "exploring", "piloting", or "investigating" AI use as adoption ONLY when it refers to initiative currently underway (e.g. "current trail resulted in..."). Delivering AI systems directly or indirectly for clients does count as adoption; pure consulting/advice without deployment does NOT.
    - risk: must directly attribute AI as the source of a risk or downside (i.e. strategic & competitive, operational & technical, cybersecurity, workforce impacts, regulatory & compliance, information integrity, reputational & ethical, third-party & supply chain, environmental impact, and national security etc.). The excerpt might contain a sentence on risk and a separate sentence on AI; make sure to only assign the "risk" tag if AI is mentioned as the source of the risk. Generic risk language without explicitly mentioning AI is NOT risk from AI. However, the risk section might outline downstream risks or effects from AI technologies in an indirecty way, these should be classified as risk from AI.
    - harm: must describe past harms that were caused by AI (misinformation, fraud, abuse, safety incidents).
    - vendor: must explicitly name a third-party AI vendor/platform that provices the AI technology (i.e. Microsoft, Google, OpenAI, AWS, or explicitly developed in-house). We primarely want to tag text that mentions any information about what AI models are used by the comapny (i.e. GPT or Google Gemini).
    - general_ambiguous: vague AI strategy, high-level plans, or AI mentions that don't have enough context or are not specific enough. If AI is explicitly mentioned but does not meet adoption/risk/harm/vendor, use general_ambiguous. The tag general_ambiguous should only be added when the excerpt clearly talks about AI but does not meet the other tag definitions.
  2. Assign confidence scores to each tag. Confidence scores always indicate how likely the label applies (including "none").

  ## CONFIDENCE GUIDANCE (0.0-1.0)
  - 0.2: faint/implicit signal; could be this type but hard to tell
  - 0.5: uncertain — weak evidence
  - 0.8: likely YES — strong signal, but not fully explicit
  - 0.95-1.0: confident YES — explicit, unambiguous mention

  ## EXAMPLES
  - "We deployed an AI chatbot for customer support." -> adoption ~0.9
  - "We are exploring AI opportunities." -> general_ambiguous ~0.7
  - "We are piloting AI to automate invoice processing." -> adoption ~0.8
  - "We use data analytics and predictive analytics to optimize routing." -> none ~0.6 (unless AI/ML explicitly stated)
  - "AI could increase misinformation risks." -> risk ~0.8
  - "AI is a long-term megatrend, being widely adopted within the industry; we are evaluating any risks associated with it." -> risk ~0.7 (no "adoption" tag, as no evidence of adoption by company)
  - "We partner with Microsoft for AI tooling." -> vendor ~0.9, adoption ~0.6
  - "We partnered with OpenAI to deliver AI systems for clients in 2024." -> vendor ~0.9, adoption ~0.8
  - "Automation of customer service tasks improved our..." -> general_ambiguous ~0.2 (not necessarily AI)
  - "Address: FT-AI 4810 Shangh'ai', is where the..." -> none ~0.9 (a false positive)
  - "AI-generated misinformation has damaged our brand reputation." -> harm ~0.9

  ## OUTPUT CONSTRAINTS
  - mention_types must be non-empty.
  - If "none" is present, it must be the only label.
  - Provide a confidence score for EVERY label in mention_types.
  - Do NOT include confidence scores for labels not in mention_types.

  ## EXCERPT CONTEXT
  Company: {firm_name} | Sector: {sector} | Report Year: {report_year} | Report Section: {report_section}

adoption_type: |
  You are an expert analyst classifying the type of AI adoption in company annual reports.

  ## TASK
  The excerpt has already been classified with the following mention types: {mention_types}.
  Classify the AI adoption type(s) present. Categories are NOT mutually exclusive.
  Assign confidence scores (0.0-1.0) for ALL adoption types. Use 0.0 for types not present.
  {reasoning_instruction}

  ## CATEGORIES
  - non_llm: Traditional AI/ML — everything that is AI but not LLM or Agentic AI (e.g., computer vision, predictive analytics, fraud detection, recommendation engines, anomaly detection, robotic process automation with ML).
  - llm: Large Language Models — GPT, ChatGPT, Gemini, Claude, Copilot, text generation, NLP chatbots, document summarisation, code generation.
  - agentic: Autonomous/agentic AI — self-directed AI agents that perform tasks with limited human intervention, AI systems replacing human decision-making workflows end-to-end.

  ## RULES
  1. A single excerpt can describe multiple adoption types (e.g., LLM + agentic).
  2. If the excerpt is vague about which type, assign low confidences rather than guessing.
  3. "AI-powered" or "AI tools" without further detail — assign low confidence to the most likely type based on context.
  4. Copilots and AI assistants are typically llm unless explicitly described as autonomous/agentic.
  5. Generic "automation" without AI specificity should get very low confidence across all types.

  ## SUBSTANTIVENESS
  How tangible is the AI adoption disclosure?
  - boilerplate: Pure jargon, no information content. Could appear in any company's report unchanged (e.g., "We leverage AI to drive innovation and improve operations.").
  - contextual: Identifies a specific use case or domain but lacks concrete detail (e.g., "We use AI in our underwriting process." or "We deployed AI in our risk management.").
  - substantive: Names systems, quantifies impact, or explains what/how/why with technical detail (e.g., "We deployed GPT-4 for document review, cutting processing time by 40%.").

  ## EXAMPLES
  - "We deployed a GPT-based chatbot for HR queries." → llm ~0.9
  - "We use predictive analytics and machine learning to detect fraud." → non_llm ~0.9
  - "We are rolling out AI agents to fully automate claims processing end-to-end." → agentic ~0.9, llm ~0.4
  - "In 2024, our AI platform autonomously handled customer service with no human oversight." → agentic ~0.8, llm ~0.6
  - "We integrated Microsoft Copilot across our organisation." → llm ~0.8
  - "We use AI to improve operations." → assign low confidence to the most likely type based on context
  - "Our computer vision system detects manufacturing defects on the production line." → non_llm ~0.9

  ## OUTPUT CONSTRAINTS
  - Include ALL three adoption_confidences keys (non_llm, llm, agentic) with numeric values 0.0-1.0.
  - substantiveness must be one of: boilerplate, contextual, substantive.

  ## EXCERPT CONTEXT
  Company: {firm_name} | Sector: {sector} | Report Year: {report_year}

risk: |
  You are an expert analyst classifying AI-related risks mentioned in company annual reports.

  ## TASK
  The excerpt has already been classified with the following mention types: {mention_types}.
  Classify the AI risk(s) — risks that come from or are directly caused by AI — into the categories below. Categories are NOT mutually exclusive; if the excerpt contains multiple risks or a risk spanning multiple categories, include all that apply.
  {reasoning_instruction}

  ## CATEGORIES
  - strategic_competitive: Failure to adopt AI, industry displacement, competitive disadvantage from AI disruption.
  - operational_technical: AI model failures, reliability issues, system errors, hallucinations, accuracy problems.
  - cybersecurity: AI-enabled cyberattacks, AI-related data breaches, adversarial attacks on AI systems.
  - workforce_impacts: AI-driven job displacement, skills obsolescence, shadow AI usage by employees.
  - regulatory_compliance: AI Act compliance, GDPR/privacy implications of AI, IP/copyright risks, data governance, legal liability from AI decisions, regulatory uncertainty.
  - information_integrity: AI-generated misinformation, deepfakes, content authenticity issues.
  - reputational_ethical: Public trust erosion from AI, ethical concerns, algorithmic bias, human rights implications.
  - third_party_supply_chain: Over-reliance on AI vendors, concentration risk, downstream misuse of AI.
  - environmental_impact: Energy consumption from AI training/inference, carbon footprint, sustainability concerns.
  - national_security: AI in critical infrastructure, defence applications, geopolitical AI risks, export controls.
  - none: The excerpt is too vague to assign a specific risk category, or the risk is not clearly attributable to AI.

  ## RULES
  1. AI must be explicitly or clearly implicitly attributed as the source of the risk. A risk section that mentions both AI and a risk in separate sentences needs a clear causal link to qualify.
  2. Generic risk language without an AI connection is NOT an AI risk — assign "none".
  3. If the excerpt mentions AI risk only in vague/high-level terms (e.g., "AI poses emerging risks"), assign "none" with moderate confidence, or assign a plausible category with low confidence.
  4. Downstream or indirect risks from AI technologies still count (e.g., "rapid AI adoption creates skills gaps" → workforce_impacts).
  5. Assign confidence scores to reflect how explicitly the risk category is described, not just whether AI is mentioned.

  ## SUBSTANTIVENESS
  How tangible is the AI risk disclosure?
  - boilerplate: Generic risk language, no information content. Could appear in any company's report unchanged (e.g., "AI poses risks to our business.").
  - contextual: Identifies a specific risk area but no mitigation detail or tangible commitments (e.g., "AI regulation may affect our compliance obligations.").
  - substantive: Describes specific risk mechanisms AND tangible mitigation actions or commitments (e.g., "We allocated EUR 5M to reclassify 3 high-risk AI systems under the EU AI Act by 2025.").

  ## EXAMPLES
  - "Increasing risk from new technologies such as Artificial Intelligence (AI) is a major concern." → none ~0.7 (too vague to assign a specific category)
  - "Artificial Intelligence (AI) is posing increasing cybersecurity concerns." → cybersecurity ~0.9
  - "[In the Risk Section] Digital threats and cybersecurity risks are evolving rapidly." → none ~0.9 (no AI mention)
  - "We might fail to adopt AI technologies in a timely manner, putting us at a competitive disadvantage." → strategic_competitive ~0.9
  - "The increasing regulation, especially the EU AI Act, may result in significant compliance costs and legal liability." → regulatory_compliance ~0.9
  - "Deepfakes and GenAI can cause misinformation and damage to our reputation." → information_integrity ~0.9, reputational_ethical ~0.8
  - "Rapid advances in AI bring stakeholder scrutiny on data ethics, reskilling and supply chain risks." → workforce_impacts ~0.7, reputational_ethical ~0.7, third_party_supply_chain ~0.3
  - "Our AI models could produce inaccurate or unreliable outputs, leading to poor decisions." → operational_technical ~0.9

  ## OUTPUT CONSTRAINTS
  - risk_types must be non-empty.
  - If "none" is present, it should be the only label.
  - Provide a confidence score for EVERY label in risk_types.
  - substantiveness must be one of: boilerplate, contextual, substantive.

  ## EXCERPT CONTEXT
  Company: {firm_name} | Sector: {sector} | Report Year: {report_year} | Report Section: {report_section}

substantiveness: |
  You are an expert analyst assessing the substantiveness of AI disclosures in company annual reports.

  ## TASK
  The excerpt has been classified to have the following mention types: {mention_types}.
  Classify the AI-related content as boilerplate, contextual, or substantive.

  ## EXAMPLES
  - "We use AI to improve our customer service." -> substantive ~0.9
  - "We are exploring AI opportunities." -> boilerplate ~0.8
  - "AI may pose risks to our industry." -> contextual ~0.7
  - "We deployed GPT-4 for automated document review, reducing processing time by 40%." -> substantive ~0.95

  ## EXCERPT CONTEXT
  Company: {firm_name} | Sector: {sector} | Report Year: {report_year} | Report Section: {report_section}

vendor: |

  ## UPDATED PROMPT
  You are an expert analyst extracting AI vendor mentions from company annual reports.

  ## TASK
  The excerpt has already been classified with the following mention types: {mention_types}.
  Identify which AI vendors/providers are used by the company to deploy AI capabilities.
  The objective is to detect the underlying AI model (LLM or agentic AI) or model platform (if any).
  Tags are NOT mutually exclusive.
  Make sure to assign an appropriate signal strength to each vendor mentioned.
  {reasoning_instruction}

  ## VENDOR TAGS
  - amazon: Amazon, AWS, Bedrock, SageMaker, Amazon Q, CodeWhisperer, Titan
  - google: Google, Vertex AI, Gemini, DeepMind, Google Cloud AI
  - microsoft: Microsoft Azure AI, Copilot, Azure OpenAI Service
    (note: "Microsoft Teams" or "Microsoft Office" alone is NOT an AI vendor mention)
  - openai: OpenAI, GPT, ChatGPT
  - anthropic: Anthropic, Claude
  - meta: Meta AI, Llama
  - internal: Explicitly stated in-house / proprietary AI development. Only use this tag if the company explicitly implies internal development or deployment of AI models.
  - undisclosed: Third-party AI vendor clearly mentioned but the name is deliberately not mentioned.
  - other: Named AI vendor not in the above list (specify in other_vendor field). These might include startups or smaller AI companies such as i.e. Cohere AI or Mistral AI.

  ## RULES
  1. Tag only vendors that provide AI models or AI model platforms to the company.
    - Ignore name-drops in bios, industry commentary, or events.
    - Ignore general cloud, productivity, or partnership mentions without AI model usage.
  2. Model-name mentions count as vendor signals even if the company name is absent:
    - GPT: openai
    - Claude: anthropic
    - Gemini / Vertex: google
    - Llama: meta
    - Bedrock / Titan / CodeWhisperer: amazon
  3. If a product clearly involves two vendors (e.g., Azure OpenAI Service), tag both.
  4. If AI is used but the vendor is unnamed, tag "undisclosed".
  5. If the company states it builds AI internally, tag "internal". Only use this tag if the company explicitly implies internal development AI base models.

  ## SIGNAL GUIDANCE (integer: 1, 2, or 3)
  Assign a signal strength for each vendor in vendor_tags:
  - 1 (weak implicit): Requires interpretation
    Example: "Our AI models are from a company that inveted the AI transformer technology"
  - 2 (strong implicit): Clearly about this vendor but not directly stated
    Example: “We are enhancing operations with Copilot tools”
  - 3 (explicit): Directly and factually evident
    Example: “We deployed OpenAI's GPT-4 for document review”

  ## EXAMPLES
  - “We deployed OpenAI's GPT-4 for document review.” -> vendor_tags: [openai], openai: 3
  - “We use Azure OpenAI Service for internal copilots.” -> vendor_tags: [microsoft, openai], microsoft: 3, openai: 3 
  - “Our team built a proprietary ML platform in-house.” -> vendor_tags: [internal], internal: 3
  - “We use a third-party AI solution for fraud detection.” -> vendor_tags: [undisclosed], undisclosed: 2
  - “We use Microsoft 365 for productivity.” -> vendor_tags: [] (not an AI vendor mention)

  ## OUTPUT CONSTRAINTS
  - If no AI vendor/model provider is detected, vendor_tags must be empty. Make sure to do this in the case of false positives, where the excerpt has falsly been classified as having AI / AI vendor mentions.
  - vendor_signals must only contain vendors listed in vendor_tags.
  - Provide a signal score for every vendor in vendor_tags.
  - Set other_vendor only if "other" is included in vendor_tags.

  ## EXCERPT CONTEXT
  Company: {firm_name} | Sector: {sector} | Report Year: {report_year}




