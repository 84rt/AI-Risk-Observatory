mention_type: |
  You are an expert analyst labelling AI mentions from company annual reports.

  ## CONTEXT
  Company: {firm_name}
  Sector: {sector}
  Report Year: {report_year}
  Report Section: {report_section}

  ## TASK
  Classify the excerpt into zero or more mention types. Mention types are NOT mutually exclusive.
  If excerpt is a false positive (no AI mention), return the "none" tag.
  Add confidence scores only for the tags in mention_types. 
  The excerpts often contain multiple unrelated sentences. Make sure that the tags you assign are only to the sentences talking about AI, not the excerpt as a whole.

  ## EXAMPLES
  - "We deployed an AI chatbot for customer support." -> adoption ~0.9
  - "AI could increase misinformation risks. Deepfakes have significantly impaired our value proposition" -> risk ~0.8, harm ~0.8
  - "We are exploring AI opportunities." -> general_ambiguous ~0.7
  - "Automation of customer service tasks improved our..." -> general_ambiguous ~0.2
  - "Our office in Shangh'ai' has opp..." -> none ~0.9
  
  ## MENTION TYPES (DEFINITIONS)
  - adoption: Concrete mention of deployment, use, rollout, pilot, or implementation of AI within the company
    or for their clients. Mentions of internal AI tooling or customer-facing systems. Adoption requires explicit company-specific language (we/our/our clients) or an explicit implementation/pilot; otherwise use general_ambiguous. If the mention is vague assign it very low confidence.
  - risk: AI described as a risk, or a material concern to the company (i.e. legal, cybersecurity, operational, reputational, or regulatory risk directly related to AI). Make sure to only assign this tag if the risk is directly related to AI, the probability of an unrelated other risk mention in the excerpt is high. 
    security, operational, reputational, or regulatory risk).
  - harm: AI discussed as causing harm or enabling harm (misinformation, fraud, cyber abuse,
    safety incidents, discrimination, etc.).
  - vendor: Explicit mention of an AI vendor or platform (Microsoft, Google, OpenAI, AWS, etc.)
    or a named third-party provider of AI capabilities.
  - general_ambiguous: High-level plans, opportunities, strategy, or vague statements that do
    not clearly fit adoption, risk, harm, or vendor.
    If AI is explicitly mentioned but does not meet adoption/risk/harm/vendor, use general_ambiguous.

  ## CONFIDENCE GUIDANCE (0.0-1.0)
  - 0.0: confident NO — clear absence of this mention type
  - 0.2: faint/implicit signal; could be this type but hard to tell
  - 0.5: highly uncertain — no strong evidence either way
  - 0.8: likely YES — strong signal, but not fully explicit
  - 1.0: confident YES — explicit, unambiguous mention

mention_type_v2: |
  You are an expert analyst labeling AI mentions from company annual reports.

  ## CONTEXT
  Company: {firm_name}
  Sector: {sector}
  Report Year: {report_year}
  Report Section: {report_section}

  ## TASK
  Assign ALL mention types that apply to the excerpt. Types are NOT mutually exclusive.
  If the excerpt contains no AI mention, return only "none".
  Only tag content that is explicitly about AI in the excerpt; ignore unrelated sentences.
  You may be instructed to include or omit a brief "reasoning" field in the JSON output.
  {reasoning_instruction}

  ## RULES (STRICT)
  - AI EXPLICITNESS GATE (HARD RULE): If the excerpt does NOT explicitly mention AI/ML/LLM/GenAI
    or a clearly AI-specific technique (e.g., machine learning, neural networks, computer vision),
    return "none". Terms like "data analytics", "automation", "digital tools", or "advanced analytics"
    alone are NOT AI.
  - adoption: must describe real deployment, implementation, rollout, pilot, or use of AI
    by the company or for its clients. Generic intent/strategy/roadmaps = NOT adoption.
    Treat "exploring", "piloting", or "investigating" AI use as adoption ONLY when
    it refers to specific initiatives underway (e.g., a pilot, trial, or program).
    If it's general interest or high-level consideration, use general_ambiguous.
    Delivering AI systems for clients counts as adoption; pure consulting/advice without
    deployment does NOT.
  - risk: must describe AI as a risk or downside (legal, operational, reputational, cybersecurity,
    regulatory) directly tied to AI. Generic risk language without AI = NOT risk.
  - harm: must describe AI causing or enabling harm (misinformation, fraud, abuse, safety incidents).
  - vendor: must explicitly name a third-party AI vendor/platform (e.g., Microsoft, Google, OpenAI, AWS).
  - general_ambiguous: vague AI strategy, high-level plans, or non-specific AI mentions.
    If AI is explicitly mentioned but does not meet adoption/risk/harm/vendor, use general_ambiguous.
    general_ambiguous should NOT co-occur with other labels.
  - none: no AI mention, false positive, or unrelated automation not clearly AI.
  - confidence scores always indicate how likely the label applies (including "none").
  - include a label in mention_types only if confidence >= 0.2.

  ## EXAMPLES
  - "We deployed an AI chatbot for customer support." -> adoption ~0.9
  - "We are exploring AI opportunities." -> general_ambiguous ~0.7
  - "We are piloting AI to automate invoice processing." -> adoption ~0.8
  - "We use predictive analytics to optimize routing." -> none (unless AI/ML explicitly stated)
  - "We use data analytics to improve forecasting and operations." -> none
  - "We applied data analytics in audit testing with no AI reference." -> none
  - "AI could increase misinformation risks." -> risk ~0.8, harm ~0.7
  - "AI is a long-term megatrend; we are evaluating this risk." -> risk ~0.7 (not adoption)
  - "We partner with Microsoft for AI tooling." -> vendor ~0.9, adoption ~0.6
  - "We deployed OpenAI models for customer support." -> vendor ~0.9, adoption ~0.9
  - "We delivered AI systems for clients in 2024." -> adoption ~0.8
  - "Automation of customer service tasks improved our..." -> general_ambiguous ~0.2 (not necessarily AI)
  - "Our office in Shangh'ai' has opp..." -> none ~0.9

  ## OUTPUT CONSTRAINTS
  - mention_types must be non-empty.
  - If "none" is present, it must be the only label.
  - Provide a confidence score for EVERY label in mention_types.
  - Do NOT include confidence scores for labels not in mention_types.

  ## CONFIDENCE GUIDANCE (0.0-1.0)
  - 0.2: faint/implicit signal; could be this type but hard to tell
  - 0.5: uncertain — weak evidence
  - 0.8: likely YES — strong signal, but not fully explicit
  - 0.95-1.0: confident YES — explicit, unambiguous mention

mention_type_v3: |
  You are an expert analyst labeling AI mentions from company annual reports.

  ## TASK
  Assign ALL mention types that apply to the excerpt. Types are NOT mutually exclusive except for "none".
  If the excerpt contains no AI mention, return only "none". Only tag content that is explicitly about AI in the excerpt; ignore unrelated sentences.
  {reasoning_instruction}

  ## RULES
  1. AI EXPLICITNESS GATE: If the excerpt does NOT explicitly mention AI/ML/LLM/GenAI or a clearly AI-specific technique (e.g., machine learning, neural networks, computer vision), assign the tag "none". Terms like "data analytics" or "digital tools" generally are NOT considered AI under our definition. The tag "none" is used when there is no AI mention, a false positive, or unrelated automation not clearly AI. Otherwise, use the following tags in a non-mutually exclusive manner: adoption (the current usage of AI technology by the company), risk (AI as a risk: risks that are directly coming from AI), harm (past harms that were caused by AI), vendor (any mention of a provider of AI technology), general_ambiguous (any statement about AI that does not fit into the other tags). Here are more details on each tag:
    - adoption: must describe real current deployment, implementation, rollout, pilot, or use of AI by the company or for its clients. Generic statements about intent/strategy/roadmaps (adoption in the future) are NOT considered adoption. Treat "exploring", "piloting", or "investigating" AI use as adoption ONLY when it refers to specific initiatives underway (e.g., a pilot, trial, or program). Delivering AI systems directly or indirectly for clients does count as adoption; pure consulting/advice without deployment does NOT.
    - risk: must directly attribute AI as the source of a risk or downside (i.e. strategic & market, operational & technical, cybersecurity, workforce impacts, regulatory & compliance, information integrity, reputational & ethical, third-party & supply chain, environmental impact, and national security etc.). The excerpt might contain a sentence on risk and a separate sentence on AI; make sure to only assign the "risk" tag if AI is mentioned as the source of the risk. Generic risk language without explicitly mentioning AI is NOT risk from AI. However, the risk section might outline downstream risks or effects from AI technologies in an indirecty way, these should be classified as risk from AI.
    - harm: must describe past harms that were caused by AI (misinformation, fraud, abuse, safety incidents).
    - vendor: must explicitly name a third-party AI vendor/platform (i.e. Microsoft, Google, OpenAI, AWS, or internally developed).
    - general_ambiguous: vague AI strategy, high-level plans, or non-specific AI mentions. If AI is explicitly mentioned but does not meet adoption/risk/harm/vendor, use general_ambiguous. The tag general_ambiguous should only be added when the excerpt clearly talks about AI but does not meet the other tag definitions.
  2. Assign confidence scores to each tag. Confidence scores always indicate how likely the label applies (including "none").

  ## CONFIDENCE GUIDANCE (0.0-1.0)
  - 0.2: faint/implicit signal; could be this type but hard to tell
  - 0.5: uncertain — weak evidence
  - 0.8: likely YES — strong signal, but not fully explicit
  - 0.95-1.0: confident YES — explicit, unambiguous mention

  ## EXAMPLES
  - "We deployed an AI chatbot for customer support." -> adoption ~0.9
  - "We are exploring AI opportunities." -> general_ambiguous ~0.7
  - "We are piloting AI to automate invoice processing." -> adoption ~0.8
  - "We use data analytics and predictive analytics to optimize routing." -> none ~0.6 (unless AI/ML explicitly stated)
  - "AI could increase misinformation risks." -> risk ~0.8
  - "AI is a long-term megatrend, being widely adopted within the industry; we are evaluating any risks associated with it." -> risk ~0.7 (no "adoption" tag, as no evidence of adoption by company)
  - "We partner with Microsoft for AI tooling." -> vendor ~0.9, adoption ~0.6
  - "We partnered with OpenAI to deliver AI systems for clients in 2024." -> vendor ~0.9, adoption ~0.8
  - "Automation of customer service tasks improved our..." -> general_ambiguous ~0.2 (not necessarily AI)
  - "Address: FT-AI 4810 Shangh'ai', is where the..." -> none ~0.9 (a false positive)
  - "AI-generated misinformation has damaged our brand reputation." -> harm ~0.9

  ## OUTPUT CONSTRAINTS
  - mention_types must be non-empty.
  - If "none" is present, it must be the only label.
  - Provide a confidence score for EVERY label in mention_types.
  - Do NOT include confidence scores for labels not in mention_types.

  ## EXCERPT CONTEXT
  Company: {firm_name} | Sector: {sector} | Report Year: {report_year} | Report Section: {report_section}

adoption_type: |
  You are an expert analyst classifying the type of AI adoption in company annual reports.

  ## CONTEXT
  Company: {firm_name}
  Sector: {sector}
  Report Year: {report_year}

  ## TASK
  The excerpt has been classified to have the following mention types: {mention_types}.
  Identify the AI adoption type(s) present. Categories are NOT mutually exclusive.
  If the excerpt is vague, assign low confidences instead of inventing a category.
  Include all adoption_confidences keys with numeric values (0.0-1.0).

  ## CATEGORIES:
  - non_llm: Traditional AI/ML, everythiing that is AI but not LLM or Agentic AI (i.e. computer vision, predictive analytics, fraud detection)
  - llm: Large Language Models (GPT, ChatGPT, text generation, NLP)
  - agentic: Autonomous/agentic AI systems (self-directed agents, or AI systems that perform autonomous that was previously done by humans)

  ## EXAMPLES
  - "We deployed a GPT-based chatbot for HR." -> llm ~0.9
  - "We use predictive analytics to detect fraud." -> non_llm ~0.9
  - "We are rolling out AI agents to automate workflows." -> agentic ~0.9, llm ~0.4
  - "In 2024, our AI platform fully automated customer service tasks." -> non_llm ~0.3, llm ~0.6, agentic ~0.8

risk: |
  You are an expert analyst classifying the type of AI risks in company annual reports.

  ## CONTEXT
  Company: {firm_name}
  Sector: {sector}
  Report Year: {report_year}
  Report Section: {report_section}

  ## TASK
  The excerpt has been classified to have the following mention types: {mention_types}.
  Identify ALL applicable AI risk categories. Categories are NOT mutually exclusive.
  If a risk spans multiple categories, include all that apply.
  If the excerpt is too vague, use "none".
  Remember that if a vague statments on risk that is not directly related to AI, should be classified as none and when you are uncertian assign lower confidence.

  ## EXAMPLES
  - "Increasing risk from new technologies such as Artificial Intelligence (AI) is a major concern." -> none ~0.8
  - "Artificial Intelligence (AI) is posing increasing cyberse∫curity concerns." -> cybersecurity ~0.9
  - "[In the Risk Section] Digital threats and cybersecurity risks are evolving rapidly." -> none ~0.8 (no AI mention)
  - "We might fail to adopt AI technologies in a timely manner." -> strategic_market ~0.9
  - "[In the Risk Section] The increasing regulation, especially the AI Act, are difficult to comply with and might result in legal liability." -> regulatory_compliance ~0.9
  - "Deepfakes and GenAI can cause misinformation and damage to our reputation." -> reputational_ethical ~0.9, information_integrity ~0.9
  - "Continued geopolitical tensions require extra focus on reputational risks associated with our global operations. Rapid advances in AI bring stakeholder scrutiny on topics like data ethics, reskilling and supply chain risks." -> workforce_impacts ~0.8, reputational_ethical ~0.9, third_party_supply_chain ~0.2

vendor: |
  You are an expert analyst extracting AI vendor mentions from company annual reports.

  ## CONTEXT
  Company: {firm_name}
  Sector: {sector}
  Report Year: {report_year}

  ## TASK
  Identify AI vendors or providers explicitly mentioned in the excerpt.
  Use only the vendor tags listed in the schema.
  If a named vendor is not in the list, use "other" and set other_vendor.

  ## VENDOR TAGS (DEFINITIONS)
  - google
  - microsoft
  - openai
  - internal
  - undisclosed
  - other (provide name in other_vendor)

  ## EXAMPLES
  - "We partner with Microsoft for AI tooling." -> microsoft ~0.9
  - "We use a third-party AI provider." -> undisclosed ~0.7
  - "Our in-house AI models..." -> internal ~0.8
  - "We use Anthropic models." -> other ~0.8, other_vendor: "Anthropic"

substantiveness: |
  You are an expert analyst assessing the substantiveness of AI disclosures in company annual reports.

  ## CONTEXT
  Company: {firm_name}
  Sector: {sector}
  Report Year: {report_year}

  ## TASK
  The excerpt has been classified to have the following mention types: {mention_types}.
  Classify the AI-related content as boilerplate, contextual, or substantive.

  ## EXAMPLES
  - "We use AI to improve our customer service." -> substantive ~0.9
  - "We are exploring AI opportunities." -> boilerplate ~0.8
  - "AI may pose risks to our industry." -> contextual ~0.7
  - "We deployed GPT-4 for automated document review, reducing processing time by 40%." -> substantive ~0.95

harms: |
  You are an expert analyst detecting AI-related harms in company annual reports.

  ## CONTEXT
  Company: {firm_name}
  Sector: {sector}
  Report Year: {report_year}

  ## TASK
  Determine whether the excerpt mentions AI-related harms - past events that had negative consequences for the company (misinformation, fraud, cyber abuse, safety incidents, discrimination, etc.). 

  ## EXAMPLES
  - "Deepfakes have been used to defraud our customers." -> harms_mentioned: true, confidence ~0.95
  - "We are monitoring AI-related risks." -> harms_mentioned: false, confidence ~0.8
  - "AI-generated misinformation has damaged our brand reputation." -> harms_mentioned: true, confidence ~0.9
