{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Golden Set Annotation Notebook\n",
        "\n",
        "Use this notebook to review preprocessed documents for the Phase 1 golden set and record human annotations that mirror model outputs. The flow is:\n",
        "\n",
        "1) Load a `run_id`'s `documents.parquet` from `data/processed/{run_id}/`.\n",
        "2) Preview documents and select spans/sections to annotate.\n",
        "3) Add annotations to an in-memory buffer.\n",
        "4) Append annotations to `data/annotations/human/annotations.parquet` (and `annotations.jsonl`) in an append-only manner, preserving run_id and document_id.\n",
        "\n",
        "Keep the file append-only. If you need to correct an entry, append a new record with the fix and an explanatory note.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using run: gs-phase1-20260107-143822\n",
            "Documents: /Users/84rt/Projects/AI Risk Observatory/data/processed/gs-phase1-20260107-143822/documents.parquet\n",
            "Annotations (parquet): /Users/84rt/Projects/AI Risk Observatory/data/annotations/human/annotations.parquet\n",
            "Annotations (jsonl):   /Users/84rt/Projects/AI Risk Observatory/data/annotations/human/annotations.jsonl\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "import json\n",
        "import uuid\n",
        "import pandas as pd\n",
        "\n",
        "# Paths\n",
        "PIPELINE_ROOT = Path(\"..\" ).resolve()\n",
        "REPO_ROOT = PIPELINE_ROOT.parent\n",
        "DATA_DIR = REPO_ROOT / \"data\"\n",
        "ANNOTATIONS_DIR = DATA_DIR / \"annotations\" / \"human\"\n",
        "ANNOTATIONS_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Configure the run to review\n",
        "RUN_ID = \"gs-phase1-20260107-143822\"  # update to the run_id you want to annotate\n",
        "DOCUMENTS_PATH = DATA_DIR / \"processed\" / RUN_ID / \"documents.parquet\"\n",
        "ANNOTATIONS_PARQUET = ANNOTATIONS_DIR / \"annotations.parquet\"\n",
        "ANNOTATIONS_JSONL = ANNOTATIONS_PARQUET.with_suffix(\".jsonl\")\n",
        "\n",
        "print(f\"Using run: {RUN_ID}\")\n",
        "print(f\"Documents: {DOCUMENTS_PATH}\")\n",
        "print(f\"Annotations (parquet): {ANNOTATIONS_PARQUET}\")\n",
        "print(f\"Annotations (jsonl):   {ANNOTATIONS_JSONL}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 26 documents\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>document_id</th>\n",
              "      <th>company_name</th>\n",
              "      <th>cni_sector</th>\n",
              "      <th>year</th>\n",
              "      <th>source_format</th>\n",
              "      <th>spans_original</th>\n",
              "      <th>spans_retained</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>00033774-2024-chemicals-ixbrl</td>\n",
              "      <td>Johnson Matthey plc</td>\n",
              "      <td>Chemicals</td>\n",
              "      <td>2024</td>\n",
              "      <td>ixbrl</td>\n",
              "      <td>18021</td>\n",
              "      <td>18021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>00033774-2023-chemicals-ixbrl</td>\n",
              "      <td>Johnson Matthey plc</td>\n",
              "      <td>Chemicals</td>\n",
              "      <td>2023</td>\n",
              "      <td>ixbrl</td>\n",
              "      <td>15773</td>\n",
              "      <td>15773</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>07524813-2024-civil-nuclear-ixbrl</td>\n",
              "      <td>Rolls-Royce Holdings plc</td>\n",
              "      <td>Civil Nuclear</td>\n",
              "      <td>2024</td>\n",
              "      <td>ixbrl</td>\n",
              "      <td>8404</td>\n",
              "      <td>8404</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                         document_id              company_name     cni_sector  \\\n",
              "0      00033774-2024-chemicals-ixbrl       Johnson Matthey plc      Chemicals   \n",
              "1      00033774-2023-chemicals-ixbrl       Johnson Matthey plc      Chemicals   \n",
              "2  07524813-2024-civil-nuclear-ixbrl  Rolls-Royce Holdings plc  Civil Nuclear   \n",
              "\n",
              "   year source_format  spans_original  spans_retained  \n",
              "0  2024         ixbrl           18021           18021  \n",
              "1  2023         ixbrl           15773           15773  \n",
              "2  2024         ixbrl            8404            8404  "
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def load_documents(path: Path) -> pd.DataFrame:\n",
        "    if not path.exists():\n",
        "        raise FileNotFoundError(f\"Documents not found: {path}\")\n",
        "    df = pd.read_parquet(path)\n",
        "    return df\n",
        "\n",
        "# Load documents for the configured run\n",
        "DOCS = load_documents(DOCUMENTS_PATH)\n",
        "print(f\"Loaded {len(DOCS)} documents\")\n",
        "DOCS.head(3)[[\n",
        "    \"document_id\",\n",
        "    \"company_name\",\n",
        "    \"cni_sector\",\n",
        "    \"year\",\n",
        "    \"source_format\",\n",
        "    \"spans_original\",\n",
        "    \"spans_retained\",\n",
        "]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "def preview_document(document_id: str, chars: int = 1200):\n",
        "    row = DOCS.loc[DOCS.document_id == document_id]\n",
        "    if row.empty:\n",
        "        raise ValueError(f\"document_id not found: {document_id}\")\n",
        "    rec = row.iloc[0].to_dict()\n",
        "    print(json.dumps({\n",
        "        \"document_id\": rec[\"document_id\"],\n",
        "        \"company\": rec[\"company_name\"],\n",
        "        \"sector\": rec[\"cni_sector\"],\n",
        "        \"year\": rec[\"year\"],\n",
        "        \"format\": rec[\"source_format\"],\n",
        "        \"spans\": rec[\"spans_original\"],\n",
        "    }, indent=2))\n",
        "    snippet = rec[\"text_markdown\"][:chars]\n",
        "    print(\"\\n--- Preview (truncated) ---\\n\")\n",
        "    print(snippet)\n",
        "\n",
        "# Example: replace with a real document_id from DOCS\n",
        "# preview_document(DOCS.iloc[0].document_id)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "annotations_buffer: list[dict] = []\n",
        "\n",
        "\n",
        "def add_annotation(\n",
        "    document_id: str,\n",
        "    *,\n",
        "    dimension: str,\n",
        "    label: str,\n",
        "    text_excerpt: str,\n",
        "    report_section: str | None = None,\n",
        "    ai_specificity: str = \"specific\",\n",
        "    frontier_tech_flag: bool = False,\n",
        "    tier_1_category: str | None = None,\n",
        "    tier_2_driver: str | None = None,\n",
        "    specificity_level: str | None = None,\n",
        "    materiality_signal: str | None = None,\n",
        "    mitigation_mentioned: bool | None = None,\n",
        "    governance_maturity: str | None = None,\n",
        "    severity: str | None = None,\n",
        "    mitigation_score: float | None = None,\n",
        "    confidence: float = 1.0,\n",
        "    classifier_id: str = \"human_golden\",\n",
        "    classifier_version: str = \"v1\",\n",
        ") -> dict:\n",
        "    \"\"\"Add one annotation record to the in-memory buffer.\"\"\"\n",
        "    row = DOCS.loc[DOCS.document_id == document_id]\n",
        "    if row.empty:\n",
        "        raise ValueError(f\"document_id not found: {document_id}\")\n",
        "    rec = row.iloc[0].to_dict()\n",
        "\n",
        "    annotation = {\n",
        "        \"annotation_id\": f\"ann-{uuid.uuid4().hex[:12]}\",\n",
        "        \"document_id\": rec[\"document_id\"],\n",
        "        \"company_number\": rec[\"company_number\"],\n",
        "        \"company_name\": rec[\"company_name\"],\n",
        "        \"ticker\": rec.get(\"ticker\"),\n",
        "        \"lei\": rec.get(\"lei\"),\n",
        "        \"cni_sector\": rec.get(\"cni_sector\"),\n",
        "        \"year\": int(rec[\"year\"]),\n",
        "        \"dimension\": dimension,  # e.g., harm | adoption | risk_disclosure\n",
        "        \"label\": label,\n",
        "        \"text_excerpt\": text_excerpt,\n",
        "        \"report_section\": report_section,\n",
        "        \"ai_specificity\": ai_specificity,\n",
        "        \"frontier_tech_flag\": frontier_tech_flag,\n",
        "        \"tier_1_category\": tier_1_category,\n",
        "        \"tier_2_driver\": tier_2_driver,\n",
        "        \"specificity_level\": specificity_level,\n",
        "        \"materiality_signal\": materiality_signal,\n",
        "        \"mitigation_mentioned\": mitigation_mentioned,\n",
        "        \"governance_maturity\": governance_maturity,\n",
        "        \"severity\": severity,\n",
        "        \"mitigation_score\": mitigation_score,\n",
        "        \"confidence\": confidence,\n",
        "        \"classifier_id\": classifier_id,\n",
        "        \"classifier_version\": classifier_version,\n",
        "        \"model_name\": None,\n",
        "        \"source\": \"human\",\n",
        "        \"run_id\": rec.get(\"run_id\"),\n",
        "        \"created_at\": datetime.utcnow().isoformat(),\n",
        "        \"raw_path\": rec.get(\"raw_path\"),\n",
        "        \"source_format\": rec.get(\"source_format\"),\n",
        "    }\n",
        "    annotations_buffer.append(annotation)\n",
        "    print(f\"Added annotation {annotation['annotation_id']} for {rec['company_name']} ({rec['year']})\")\n",
        "    return annotation\n",
        "\n",
        "\n",
        "def append_annotations_buffer():\n",
        "    \"\"\"Append buffered annotations to parquet/jsonl (append-only).\"\"\"\n",
        "    if not annotations_buffer:\n",
        "        print(\"Buffer is empty; nothing to write.\")\n",
        "        return\n",
        "\n",
        "    new_df = pd.DataFrame(annotations_buffer)\n",
        "\n",
        "    if ANNOTATIONS_PARQUET.exists():\n",
        "        existing = pd.read_parquet(ANNOTATIONS_PARQUET)\n",
        "        combined = pd.concat([existing, new_df], ignore_index=True)\n",
        "    else:\n",
        "        combined = new_df\n",
        "\n",
        "    combined.to_parquet(ANNOTATIONS_PARQUET, index=False)\n",
        "    combined.to_json(ANNOTATIONS_JSONL, orient=\"records\", lines=True)\n",
        "\n",
        "    print(f\"Appended {len(new_df)} annotations (total now {len(combined)})\")\n",
        "    annotations_buffer.clear()\n",
        "\n",
        "\n",
        "def list_recent_annotations(limit: int = 5):\n",
        "    if not ANNOTATIONS_PARQUET.exists():\n",
        "        print(\"No annotations written yet.\")\n",
        "        return\n",
        "    df = pd.read_parquet(ANNOTATIONS_PARQUET)\n",
        "    display(df.tail(limit))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example workflow (replace values before running)\n",
        "# doc_id = DOCS.iloc[0].document_id\n",
        "# preview_document(doc_id)\n",
        "# add_annotation(\n",
        "#     document_id=doc_id,\n",
        "#     dimension=\"risk_disclosure\",\n",
        "#     label=\"cybersecurity\",\n",
        "#     text_excerpt=\"Paste the exact quote you are labeling\",\n",
        "#     page_number=12,\n",
        "#     report_section=\"principal_risks\",\n",
        "#     ai_specificity=\"specific\",\n",
        "#     specificity_level=\"specific\",\n",
        "#     mitigation_mentioned=True,\n",
        "#     severity=\"high\",\n",
        "#     confidence=0.95,\n",
        "#     annotator=\"your_name\",\n",
        "# )\n",
        "# append_annotations_buffer()\n",
        "# list_recent_annotations()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Helper widgets for fast annotation\n",
        "Use these widgets to filter documents, preview quickly, and add annotations with minimal typing. Adjust options if you add new dimensions/labels later.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wrote human-readable markdown to current_doc.md\n"
          ]
        }
      ],
      "source": [
        "# Generate the doc\n",
        "import textwrap\n",
        "from pathlib import Path\n",
        "\n",
        "def normalize_markdown(md: str, width: int = 100) -> str:\n",
        "    # Split on blank lines to keep paragraph breaks, then wrap each paragraph\n",
        "    paragraphs = md.split(\"\\n\\n\")\n",
        "    wrapped = [\n",
        "        \"\\n\".join(textwrap.fill(line, width) for line in para.splitlines())\n",
        "        for para in paragraphs\n",
        "    ]\n",
        "    return \"\\n\\n\".join(wrapped)\n",
        "\n",
        "row = DOCS.loc[DOCS.document_id == doc_dd.value].iloc[0]\n",
        "clean_md = normalize_markdown(row[\"text_markdown\"], width=100)\n",
        "tmp_path = Path(\"current_doc.md\")\n",
        "tmp_path.write_text(clean_md)\n",
        "print(f\"Wrote human-readable markdown to {tmp_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Run gs-phase1-20260107-143822: 3/26 documents have at least one human annotation.\n",
            "Buffer (unsaved) annotations: 0\n"
          ]
        }
      ],
      "source": [
        "# Progress helper: counts annotations already saved for this run_id\n",
        "import os\n",
        "\n",
        "existing_ann = None\n",
        "if ANNOTATIONS_PARQUET.exists():\n",
        "    existing_ann = pd.read_parquet(ANNOTATIONS_PARQUET)\n",
        "\n",
        "def show_progress(run_id: str = RUN_ID):\n",
        "    total_docs = len(DOCS)\n",
        "    saved = 0\n",
        "    if existing_ann is not None:\n",
        "        saved = existing_ann[existing_ann[\"run_id\"] == run_id][\"document_id\"].nunique()\n",
        "    print(f\"Run {run_id}: {saved}/{total_docs} documents have at least one human annotation.\")\n",
        "    print(f\"Buffer (unsaved) annotations: {len(annotations_buffer)}\")\n",
        "\n",
        "show_progress()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "81aa102142e54924bbe4bd5ec89d8e4d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(HBox(children=(Dropdown(description='Company', options=('(all)', 'AstraZeneca plc', 'BAE System…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c647f1f470bd4e4e8b63c79dd27eb580",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Output()"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "\n",
        "META_COLS = [\"document_id\", \"company_name\", \"cni_sector\", \"year\", \"source_format\"]\n",
        "DOCS_META = DOCS[META_COLS].copy()\n",
        "\n",
        "DIMENSION_OPTIONS = [\"risk_disclosure\", \"harm\", \"adoption\", \"vendor\"]\n",
        "\n",
        "# Taxonomy-driven labels per dimension (from choices_report)\n",
        "LABEL_OPTIONS = {\n",
        "    \"risk_disclosure\": [\n",
        "        \"operational_technical\",\n",
        "        \"cybersecurity\",\n",
        "        \"workforce_impacts\",\n",
        "        \"regulatory_compliance\",\n",
        "        \"information_integrity\",\n",
        "        \"reputational_ethical\",\n",
        "        \"third_party_supply_chain\",\n",
        "        \"environmental_impact\",\n",
        "        \"national_security\",\n",
        "    ],\n",
        "    \"harm\": [\"mentioned\", \"not_mentioned\"],\n",
        "    \"adoption\": [\"non_llm\", \"llm\", \"agentic_ai\"],\n",
        "    \"vendor\": [\n",
        "        \"internal / opensource\",\n",
        "        \"Microsoft\",\n",
        "        \"OpenAI\",\n",
        "        \"Google\",\n",
        "        \"Anthropic\",\n",
        "        \"Mistral\",\n",
        "        \"unspecified\",\n",
        "        \"other\",\n",
        "    ],\n",
        "    # Substantiveness is only used as a property of risk_disclosure\n",
        "    \"substantiveness\": [\"boilerplate\", \"substantive\"],\n",
        "}\n",
        "\n",
        "# Dimension dropdown (added to fix NameError)\n",
        "dim_dd = widgets.Dropdown(description=\"dimension\", options=DIMENSION_OPTIONS, value=DIMENSION_OPTIONS[0])\n",
        "\n",
        "companies = sorted(DOCS_META.company_name.unique())\n",
        "years = sorted(DOCS_META.year.unique())\n",
        "\n",
        "company_dd = widgets.Dropdown(options=[\"(all)\"] + companies, description=\"Company\")\n",
        "year_dd = widgets.Dropdown(options=[\"(all)\"] + [int(y) for y in years], description=\"Year\")\n",
        "doc_dd = widgets.Dropdown(options=[], description=\"document_id\", layout=widgets.Layout(width=\"60%\"))\n",
        "preview_out = widgets.Output()\n",
        "\n",
        "def _refresh_doc_options(*_):\n",
        "    company = None if company_dd.value == \"(all)\" else company_dd.value\n",
        "    year = None if year_dd.value == \"(all)\" else int(year_dd.value)\n",
        "    df = DOCS_META\n",
        "    if company:\n",
        "        df = df[df.company_name == company]\n",
        "    if year:\n",
        "        df = df[df.year == year]\n",
        "    df = df.sort_values([\"company_name\", \"year\", \"document_id\"])\n",
        "    options = [(f\"{r.company_name} {r.year} ({r.source_format})\", r.document_id) for r in df.itertuples()]\n",
        "    doc_dd.options = options\n",
        "    if options:\n",
        "        doc_dd.value = options[0][1]\n",
        "\n",
        "def _on_preview(_):\n",
        "    preview_out.clear_output()\n",
        "    if not doc_dd.value:\n",
        "        return\n",
        "    with preview_out:\n",
        "        preview_document(doc_dd.value, chars=1800)\n",
        "\n",
        "company_dd.observe(_refresh_doc_options, names=\"value\")\n",
        "year_dd.observe(_refresh_doc_options, names=\"value\")\n",
        "doc_dd.observe(_on_preview, names=\"value\")\n",
        "\n",
        "_refresh_doc_options()\n",
        "\n",
        "controls = widgets.VBox([\n",
        "    widgets.HBox([company_dd, year_dd]),\n",
        "    doc_dd,\n",
        "    widgets.Button(description=\"Preview\", button_style=\"info\", tooltip=\"Preview selected document\", on_click=_on_preview),\n",
        "])\n",
        "\n",
        "display(controls, preview_out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9d598e4da8fd4e0ab15df8f73b9bedf3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(HBox(children=(Dropdown(description='dimension', options=('risk_disclosure', 'harm', 'adoption'…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3467e413b7bb47e1adadb0bcc50f3d27",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Output()"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Quick add form to minimize typing (dropdowns + substantiveness confidence)\n",
        "label_dd = widgets.Dropdown(description=\"label\", options=LABEL_OPTIONS[dim_dd.value], layout=widgets.Layout(width=\"50%\"))\n",
        "substance_dd = widgets.Dropdown(description=\"substantiveness\", options=LABEL_OPTIONS[\"substantiveness\"], value=\"substantive\")\n",
        "confidence_input = widgets.FloatSlider(description=\"confidence\", min=0.0, max=1.0, step=0.05, value=0.95)\n",
        "substance_conf_input = widgets.FloatSlider(description=\"subst. conf\", min=0.0, max=1.0, step=0.05, value=0.9)\n",
        "excerpt_ta = widgets.Textarea(description=\"excerpt\", layout=widgets.Layout(width=\"80%\", height=\"120px\"))\n",
        "section_input = widgets.Text(description=\"section\", placeholder=\"e.g., principal_risks\")\n",
        "\n",
        "# Show substantiveness controls only when dimension == risk_disclosure\n",
        "substance_box = widgets.HBox([substance_dd, substance_conf_input])\n",
        "substance_box.layout.display = \"flex\" if dim_dd.value == \"risk_disclosure\" else \"none\"\n",
        "\n",
        "add_out = widgets.Output()\n",
        "\n",
        "\n",
        "def _on_dimension_change(change):\n",
        "    if change[\"name\"] == \"value\":\n",
        "        label_dd.options = LABEL_OPTIONS.get(change[\"new\"], [])\n",
        "        if label_dd.options:\n",
        "            label_dd.value = label_dd.options[0]\n",
        "        # Toggle substantiveness controls only for risk_disclosure\n",
        "        substance_box.layout.display = \"flex\" if change[\"new\"] == \"risk_disclosure\" else \"none\"\n",
        "\n",
        "dim_dd.observe(_on_dimension_change, names=\"value\")\n",
        "\n",
        "\n",
        "def _on_add_click(_):\n",
        "    add_out.clear_output()\n",
        "    if not doc_dd.value:\n",
        "        with add_out:\n",
        "            print(\"Select a document first.\")\n",
        "        return\n",
        "    with add_out:\n",
        "        ann = add_annotation(\n",
        "            document_id=doc_dd.value,\n",
        "            dimension=dim_dd.value,\n",
        "            label=label_dd.value,\n",
        "            text_excerpt=excerpt_ta.value.strip(),\n",
        "            report_section=section_input.value.strip() or None,\n",
        "            confidence=float(confidence_input.value),\n",
        "            # Map substantiveness into fields for risk_disclosure context\n",
        "            tier_1_category=label_dd.value if dim_dd.value == \"risk_disclosure\" else None,\n",
        "            specificity_level=substance_dd.value if dim_dd.value == \"risk_disclosure\" else None,\n",
        "            mitigation_score=float(substance_conf_input.value) if dim_dd.value == \"risk_disclosure\" else None,\n",
        "        )\n",
        "        print(f\"Buffered annotation {ann['annotation_id']} for {ann['document_id']}\")\n",
        "        # Light reset\n",
        "        excerpt_ta.value = \"\"\n",
        "\n",
        "add_btn = widgets.Button(description=\"Add annotation\", button_style=\"success\")\n",
        "add_btn.on_click(_on_add_click)\n",
        "\n",
        "form = widgets.VBox([\n",
        "    widgets.HBox([dim_dd, label_dd]),\n",
        "    excerpt_ta,\n",
        "    widgets.HBox([section_input]),\n",
        "    widgets.HBox([confidence_input]),\n",
        "    substance_box,\n",
        "    add_btn,\n",
        "])\n",
        "\n",
        "display(form, add_out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Buffer is empty; nothing to write.\n"
          ]
        }
      ],
      "source": [
        "# Persist buffered annotations (append-only)\n",
        "append_annotations_buffer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total annotations: 0\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>annotation_id</th>\n",
              "      <th>document_id</th>\n",
              "      <th>company_number</th>\n",
              "      <th>company_name</th>\n",
              "      <th>ticker</th>\n",
              "      <th>lei</th>\n",
              "      <th>cni_sector</th>\n",
              "      <th>year</th>\n",
              "      <th>dimension</th>\n",
              "      <th>label</th>\n",
              "      <th>...</th>\n",
              "      <th>classifier_id</th>\n",
              "      <th>classifier_version</th>\n",
              "      <th>model_name</th>\n",
              "      <th>source</th>\n",
              "      <th>run_id</th>\n",
              "      <th>created_at</th>\n",
              "      <th>annotator</th>\n",
              "      <th>notes</th>\n",
              "      <th>raw_path</th>\n",
              "      <th>source_format</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>0 rows × 34 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [annotation_id, document_id, company_number, company_name, ticker, lei, cni_sector, year, dimension, label, text_excerpt, page_number, report_section, ai_specificity, frontier_tech_flag, tier_1_category, tier_2_driver, specificity_level, materiality_signal, mitigation_mentioned, governance_maturity, severity, mitigation_score, confidence, classifier_id, classifier_version, model_name, source, run_id, created_at, annotator, notes, raw_path, source_format]\n",
              "Index: []\n",
              "\n",
              "[0 rows x 34 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Last JSONL entries:\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Quick sanity check: show last annotations and last JSONL lines\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "if ANNOTATIONS_PARQUET.exists():\n",
        "    df_check = pd.read_parquet(ANNOTATIONS_PARQUET)\n",
        "    print(f\"Total annotations: {len(df_check)}\")\n",
        "    display(df_check.tail(5))\n",
        "else:\n",
        "    print(f\"Parquet not found: {ANNOTATIONS_PARQUET}\")\n",
        "\n",
        "if ANNOTATIONS_JSONL.exists():\n",
        "    lines = Path(ANNOTATIONS_JSONL).read_text(encoding=\"utf-8\").splitlines()\n",
        "    print(\"\\nLast JSONL entries:\")\n",
        "    for line in lines[-5:]:\n",
        "        print(line)\n",
        "else:\n",
        "    print(f\"JSONL not found: {ANNOTATIONS_JSONL}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "vscode": {
          "languageId": "bat"
        }
      },
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "invalid syntax (1021596069.py, line 1)",
          "output_type": "error",
          "traceback": [
            "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[38]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mpython3 pipeline/scripts/load_golden_to_db.py --run-id gs-phase1-20260107-143822\u001b[39m\n            ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "python3 pipeline/scripts/load_golden_to_db.py --run-id gs-phase1-20260107-143822"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
